{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7600561,"sourceType":"datasetVersion","datasetId":4424547}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import save_image, make_grid\nimport torchvision.transforms as T\n\n# --- Utilities ---\n\ndef exists(x):\n    return x is not None\n\nclass EMA:\n    def __init__(self, model: nn.Module, beta=0.9999):\n        self.beta = beta\n        self.model = model\n        self.shadow = {name: p.clone().detach() for name, p in model.named_parameters() if p.requires_grad}\n\n    def update(self):\n        for name, p in self.model.named_parameters():\n            if not p.requires_grad:\n                continue\n            s = self.shadow[name]\n            s.sub_((1 - self.beta) * (s - p.detach()))\n\n    def store(self, path: str):\n        torch.save(self.shadow, path)\n\n    def copy_to(self, model: nn.Module):\n        for name, p in model.named_parameters():\n            if name in self.shadow:\n                p.data.copy_(self.shadow[name].data)\n\n# --- Noise Schedule (Cosine) ---\n\ndef make_cosine_schedule(timesteps: int, s=0.008):\n    steps = timesteps + 1\n    t = torch.linspace(0, timesteps, steps)\n    f = torch.cos(((t / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n    alphas_cumprod = f / f[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    betas = torch.clamp(betas, 0.0001, 0.999)\n    return betas\n\nclass DiffusionSchedule:\n    def __init__(self, timesteps: int):\n        self.timesteps = timesteps\n        device = torch.device('cpu')\n        betas = make_cosine_schedule(timesteps).to(device)\n        alphas = 1. - betas\n        alphas_cumprod = torch.cumprod(alphas, dim=0)\n        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n\n        self.betas = betas\n        self.alphas = alphas\n        self.alphas_cumprod = alphas_cumprod\n        self.alphas_cumprod_prev = alphas_cumprod_prev\n        self.sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod)\n        self.posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n        \n        # Precompute coefficients for sampling\n        self.posterior_mean_coef1 = (betas * torch.sqrt(alphas_cumprod_prev) / (1 - alphas_cumprod))\n        self.posterior_mean_coef2 = ((1 - alphas_cumprod_prev) * torch.sqrt(alphas) / (1 - alphas_cumprod))\n\n    def to(self, device):\n        for k, v in self.__dict__.items():\n            if isinstance(v, torch.Tensor):\n                self.__dict__[k] = v.to(device)\n        return self","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:23:56.262840Z","iopub.execute_input":"2025-11-13T10:23:56.263582Z","iopub.status.idle":"2025-11-13T10:24:07.860076Z","shell.execute_reply.started":"2025-11-13T10:23:56.263553Z","shell.execute_reply":"2025-11-13T10:24:07.859204Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport os\n\n# --- This cell now inspects your .npy file directly ---\n\nLABELS_NPY_PATH = '/kaggle/input/pixel-art/sprites_labels.npy'\nSPRITES_NPY_PATH = '/kaggle/input/pixel-art/sprites.npy'\n\ntry:\n    print(f\"Loading labels from {LABELS_NPY_PATH}...\")\n    labels = np.load(LABELS_NPY_PATH)\n    print(f\"Labels loaded. Shape: {labels.shape}\")\n\n    # Also load sprites to check for N mismatch\n    sprites = np.load(SPRITES_NPY_PATH)\n    print(f\"Sprites loaded. Shape: {sprites.shape}\")\n\n    if labels.shape[0] != sprites.shape[0]:\n        print(f\"‚ö†Ô∏è Warning: Mismatch in item count!\")\n        print(f\"Sprites: {sprites.shape[0]} items\")\n        print(f\"Labels: {labels.shape[0]} items\")\n\n    # --- Auto-detect label format ---\n    if labels.ndim == 2:\n        # This is One-Hot format, e.g., (N, 5)\n        print(\"Detected One-Hot label format.\")\n        NUM_CLASSES = labels.shape[1] # e.g., 5\n    elif labels.ndim == 1:\n        # This is Integer format, e.g., (N,)\n        print(\"Detected Integer label format.\")\n        NUM_CLASSES = np.max(labels) + 1 # e.g., max is 4, so 5 classes\n    else:\n        raise ValueError(f\"Unexpected label dimension: {labels.ndim}\")\n        \n    print(f\"‚úÖ Found {NUM_CLASSES} classes.\")\n    print(f\"The 'null' class index for CFG will be: {NUM_CLASSES}\")\n    \n    print(\"\\n---\")\n    print(f\"‚û°Ô∏è Copy this 'NUM_CLASSES' value ({NUM_CLASSES}) into Cell 6.\")\n\nexcept FileNotFoundError:\n    print(f\"‚ùå Error: Could not find {LABELS_NPY_PATH} or {SPRITES_NPY_PATH}\")\n    print(\"Please check your file paths.\")\nexcept Exception as e:\n    print(f\"‚ùå Error inspecting labels: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:24:18.059529Z","iopub.execute_input":"2025-11-13T10:24:18.059845Z","iopub.status.idle":"2025-11-13T10:24:18.107991Z","shell.execute_reply.started":"2025-11-13T10:24:18.059823Z","shell.execute_reply":"2025-11-13T10:24:18.107334Z"}},"outputs":[{"name":"stdout","text":"Loading labels from /kaggle/input/pixel-art/sprites_labels.npy...\nLabels loaded. Shape: (89400, 5)\nSprites loaded. Shape: (89400, 16, 16, 3)\nDetected One-Hot label format.\n‚úÖ Found 5 classes.\nThe 'null' class index for CFG will be: 5\n\n---\n‚û°Ô∏è Copy this 'NUM_CLASSES' value (5) into Cell 6.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class PixelArtDataset(Dataset):\n    def __init__(self, npy_path: str, labels_path: str, image_size=16, augment=False):\n        data = np.load(npy_path)\n        if data.dtype == np.uint8:\n            data = data.astype(np.float32) / 255.0\n        \n        # data = np.transpose(data, (0, 3, 1, 2)) # <-- DELETE THIS LINE\n        \n        self.x = data.astype(np.float32) # self.x is now (N, H, W, C)\n        \n        # --- Updated Label Loading ---\n        raw_labels = np.load(labels_path)\n        \n        if raw_labels.ndim == 2:\n            # Convert from One-Hot [1,0,0] to Integer 0\n            print(\"Converting one-hot labels to integers.\")\n            self.labels = np.argmax(raw_labels, axis=1)\n        else:\n            # Labels are already Integers\n            self.labels = raw_labels\n        # ---\n        \n        self.image_size = image_size\n        self.augment = augment\n        self.transform = T.Compose([\n            T.ToPILImage(), # Now correctly receives (H, W, C)\n            T.Resize(image_size, interpolation=Image.NEAREST), # NEAREST for pixel art\n            T.ToTensor(),   # This converts the PIL Image to (C, H, W)\n        ])\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        # self.x[idx] is now (H, W, C)\n        img = (self.x[idx] * 255).astype(np.uint8) \n        \n        # This transform pipeline now works perfectly\n        img = self.transform(img) \n        \n        if self.augment:\n            if torch.rand(1) < 0.5:\n                img = T.functional.hflip(img)\n        \n        label = self.labels[idx]\n        return img, torch.tensor(label, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:24:29.707938Z","iopub.execute_input":"2025-11-13T10:24:29.708743Z","iopub.status.idle":"2025-11-13T10:24:29.716865Z","shell.execute_reply.started":"2025-11-13T10:24:29.708713Z","shell.execute_reply":"2025-11-13T10:24:29.716156Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#\n# --- üîΩüîΩüîΩ REPLACE YOUR CELL 4 WITH THIS üîΩüîΩüîΩ ---\n#\n\nclass SiLU(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_ch, out_ch, time_emb_dim):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n        self.norm1 = nn.GroupNorm(8, out_ch)\n        self.norm2 = nn.GroupNorm(8, out_ch)\n        self.act = SiLU()\n        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n        \n        # Time and Class embeddings are combined *before* this block\n        self.time_mlp = nn.Sequential(nn.Linear(time_emb_dim, out_ch), SiLU())\n\n    def forward(self, x, t_emb):\n        h = self.conv1(x)\n        h = self.norm1(h)\n        h = self.act(h)\n        h = h + self.time_mlp(t_emb).view(h.shape[0], -1, 1, 1)\n        h = self.conv2(h)\n        h = self.norm2(h)\n        return self.act(h + self.skip(x))\n\nclass AttentionBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.norm = nn.GroupNorm(8, channels)\n        self.q = nn.Conv1d(channels, channels, 1)\n        self.k = nn.Conv1d(channels, channels, 1)\n        self.v = nn.Conv1d(channels, channels, 1)\n        self.proj_out = nn.Conv1d(channels, channels, 1)\n\n    def forward(self, x):\n        b, c, h, w = x.shape\n        x_in = x\n        x = self.norm(x)\n        x = x.view(b, c, h * w)\n        q = self.q(x)\n        k = self.k(x)\n        v = self.v(x)\n        w_ = torch.bmm(q.permute(0, 2, 1), k) * (c ** (-0.5))\n        w_ = torch.softmax(w_, dim=-1)\n        out = torch.bmm(w_, v.permute(0, 2, 1)).permute(0, 2, 1)\n        out = self.proj_out(out)\n        out = out.view(b, c, h, w)\n        return out + x_in\n\nclass ContextUNet(nn.Module):\n    def __init__(self, in_ch=3, base_ch=64, channel_mults=(1, 2, 2), num_res_blocks=2, \n                 img_size=16, num_classes=10):\n        super().__init__()\n        self.in_ch = in_ch\n        self.base_ch = base_ch\n        self.num_classes = num_classes\n        time_emb_dim = base_ch * 4\n        \n        self.time_mlp = nn.Sequential(\n            nn.Linear(1, time_emb_dim), SiLU(), \n            nn.Linear(time_emb_dim, time_emb_dim)\n        )\n        \n        self.label_emb = nn.Embedding(num_classes + 1, time_emb_dim)\n        \n        chs = [base_ch] + [base_ch * m for m in channel_mults]\n        self.init_conv = nn.Conv2d(in_ch, chs[0], 3, padding=1)\n\n        # Down\n        self.downs = nn.ModuleList()\n        in_channels = chs[0]\n        use_attention = (False, True, True) \n        for i in range(len(channel_mults)):\n            out_channels = chs[i+1]\n            blocks = nn.ModuleList()\n            for _ in range(num_res_blocks):\n                blocks.append(ResidualBlock(in_channels, out_channels, time_emb_dim))\n                in_channels = out_channels\n            attn = AttentionBlock(out_channels) if use_attention[i] else nn.Identity()\n            self.downs.append(nn.ModuleDict({\n                'blocks': blocks,\n                'attn': attn,\n                'downsample': nn.AvgPool2d(2) if (i < len(channel_mults) - 1) else nn.Identity()\n            }))\n\n        # Middle\n        self.mid = nn.ModuleDict({\n            'block1': ResidualBlock(in_channels, in_channels, time_emb_dim),\n            'attn': AttentionBlock(in_channels),\n            'block2': ResidualBlock(in_channels, in_channels, time_emb_dim)\n        })\n\n        # Up\n        self.ups = nn.ModuleList()\n        for i in reversed(range(len(channel_mults))):\n            out_channels = chs[i]\n            skip_channels = chs[i+1]\n            \n            blocks = nn.ModuleList()\n            # --- BUG FIX 2: Corrected 'in_channels' logic for each block ---\n            for j in range(num_res_blocks + 1):\n                if j == 0:\n                    # First block after concat\n                    block_in_ch = in_channels + skip_channels\n                else:\n                    # Subsequent blocks\n                    block_in_ch = out_channels\n                \n                blocks.append(ResidualBlock(block_in_ch, out_channels, time_emb_dim))\n\n            # 'in_channels' for the next up-loop-level is 'out_channels' of this level\n            in_channels = out_channels\n            # --- End of BUG FIX 2 ---\n            \n            attn = AttentionBlock(out_channels) if use_attention[i] else nn.Identity()\n            \n            # --- BUG FIX 1: Corrected 'upsample' logic ---\n            # Was: if (i > 0)\n            # Should be: if (i < len(channel_mults) - 1) to mirror downsampling\n            upsample = nn.Upsample(scale_factor=2, mode='nearest') if (i < len(channel_mults) - 1) else nn.Identity()\n            # --- End of BUG FIX 1 ---\n            \n            self.ups.append(nn.ModuleDict({\n                'blocks': blocks,\n                'attn': attn,\n                'upsample': upsample\n            }))\n\n        self.out_conv = nn.Sequential(\n            nn.GroupNorm(8, base_ch),\n            SiLU(),\n            nn.Conv2d(base_ch, in_ch, 3, padding=1)\n        )\n\n    def forward(self, x, t_norm, c):\n        B = x.shape[0]\n        t = t_norm.view(B, 1)\n        t_emb = self.time_mlp(t)\n        c_emb = self.label_emb(c)\n        emb = t_emb + c_emb\n\n        hs = []\n        h = self.init_conv(x)\n        hs.append(h)\n        \n        for layer in self.downs:\n            for block in layer['blocks']:\n                h = block(h, emb)\n            h = layer['attn'](h)\n            hs.append(h)\n            h = layer['downsample'](h)\n\n        h = self.mid['block1'](h, emb)\n        h = self.mid['attn'](h)\n        h = self.mid['block2'](h, emb)\n\n        for layer in self.ups:\n            h = layer['upsample'](h)\n            skip = hs.pop()\n            h = torch.cat([h, skip], dim=1) # This line should now work\n            for block in layer['blocks']:\n                h = block(h, emb)\n            h = layer['attn'](h)\n\n        out = self.out_conv(h)\n        return out\n\n#\n# --- üîºüîºüîº REPLACE YOUR CELL 4 WITH THIS üîºüîºüîº ---\n#","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:24:34.465765Z","iopub.execute_input":"2025-11-13T10:24:34.466381Z","iopub.status.idle":"2025-11-13T10:24:34.485585Z","shell.execute_reply.started":"2025-11-13T10:24:34.466354Z","shell.execute_reply":"2025-11-13T10:24:34.484899Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"@torch.no_grad()\ndef sample_loop(model: ContextUNet, schedule: DiffusionSchedule, img_size: int, n_samples: int, \n                cond_label: int, null_class_idx: int, guidance_scale: float, device='cuda'):\n    \n    model.eval()\n    T = schedule.timesteps\n    shape = (n_samples, 3, img_size, img_size)\n    x = torch.randn(shape, device=device)\n    \n    # The class label you want to generate\n    c = torch.full((n_samples,), cond_label, dtype=torch.long, device=device)\n    # The unconditional \"null\" label\n    c_uncond = torch.full((n_samples,), null_class_idx, dtype=torch.long, device=device)\n\n    for i in tqdm(range(T - 1, -1, -1), desc=f\"Sampling (w={guidance_scale})\", leave=False):\n        t_norm = torch.full((n_samples,), i / T, device=device)\n        \n        # 1. Get conditional prediction (with label)\n        eps_cond = model(x, t_norm, c)\n        \n        # 2. Get unconditional prediction (with \"null\" label)\n        eps_uncond = model(x, t_norm, c_uncond)\n        \n        # 3. Combine them using the guidance scale\n        eps = eps_uncond + guidance_scale * (eps_cond - eps_uncond)\n        \n        # --- DDIM-like sampling step ---\n        sqrt_alphas_cumprod = schedule.sqrt_alphas_cumprod[i].to(device)\n        sqrt_one_minus = schedule.sqrt_one_minus_alphas_cumprod[i].to(device)\n        \n        # Predict x0\n        x0_pred = (x - sqrt_one_minus * eps) / sqrt_alphas_cumprod\n        x0_pred = x0_pred.clamp(-1., 1.)\n        \n        # Get mean and variance\n        posterior_mean = (\n            schedule.posterior_mean_coef1[i].to(device) * x0_pred +\n            schedule.posterior_mean_coef2[i].to(device) * x\n        )\n        \n        if i > 0:\n            noise = torch.randn_like(x)\n            var = schedule.posterior_variance[i].to(device)\n            x = posterior_mean + torch.sqrt(var) * noise\n        else:\n            x = posterior_mean # No noise at final step\n            \n    model.train() # Set back to train mode\n    return x.clamp(-1, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:24:39.245837Z","iopub.execute_input":"2025-11-13T10:24:39.246126Z","iopub.status.idle":"2025-11-13T10:24:39.254556Z","shell.execute_reply.started":"2025-11-13T10:24:39.246103Z","shell.execute_reply":"2025-11-13T10:24:39.253867Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ----------------- Hyperparameters -----------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# --- üîΩüîΩüîΩ EDIT THIS üîΩüîΩüîΩ ---\n# Get this value from running Cell 2\nYOUR_NUM_CLASSES = 5 # Example value, change this!\n# --- üîºüîºüîº EDIT THIS üîºüîºüîº ---\n\ntimesteps = 1000\nbatch_size = 128\nimg_size = 16 # Keep this low for pixel art\nlr = 2e-4\nn_epochs = 100 # Increase this for better results (e.g., 100-200)\nbase_ch = 64\np_uncond = 0.1 # Probability of dropping label for CFG (10%)\nsave_dir = '/kaggle/working/pixel_diffusion_outputs'\nos.makedirs(save_dir, exist_ok=True)\n\n# The \"null\" class ID is just the number of classes\n# (e.g., if you have 50 classes 0-49, the null ID is 50)\nNULL_CLASS_IDX = YOUR_NUM_CLASSES\n\n# dataset paths (Kaggle)\ndata_npy = '/kaggle/input/pixel-art/sprites.npy'\nlabels_npy = '/kaggle/input/pixel-art/sprites_labels.npy'\n\n# 1. Load Data\ntry:\n    dataset = PixelArtDataset(data_npy, labels_npy, image_size=img_size, augment=True)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    print(f\"Loaded dataset with {len(dataset)} images.\")\nexcept Exception as e:\n    print(f\"‚ùå Error loading dataset: {e}\")\n    print(\"Please check file paths and ensure Cell 3 is correct.\")\n    # Stop execution if data fails\n    raise e\n\n# 2. Build Schedule\nschedule = DiffusionSchedule(timesteps).to(device)\n\n# 3. Build Model\n# Pass the correct num_classes\nmodel = ContextUNet(\n    in_ch=3, \n    base_ch=base_ch, \n    channel_mults=(1, 2, 2), \n    img_size=img_size, \n    num_classes=YOUR_NUM_CLASSES\n).to(device)\nema = EMA(model, beta=0.9995)\n\nprint(f\"Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n# This line is correct\nscaler = torch.amp.GradScaler(device='cuda')\n\n# 4. Training Loop\nglobal_step = 0\nfor epoch in range(n_epochs):\n    model.train()\n    pbar = tqdm(dataloader)\n    pbar.set_description(f\"Epoch {epoch}/{n_epochs}\")\n    \n    for x, c in pbar:\n        x = x.to(device) * 2 - 1 # Normalize to [-1, 1]\n        c = c.to(device)\n        b = x.shape[0]\n\n        # --- Classifier-Free Guidance Training ---\n        uncond_mask = (torch.rand(b, device=device) < p_uncond)\n        c[uncond_mask] = NULL_CLASS_IDX\n        # ---\n\n        t_idx = torch.randint(0, timesteps, (b,), device=device)\n        noise = torch.randn_like(x)\n        \n        sqrt_alpha_cumprod = schedule.sqrt_alphas_cumprod[t_idx].view(-1, 1, 1, 1)\n        sqrt_one_minus = schedule.sqrt_one_minus_alphas_cumprod[t_idx].view(-1, 1, 1, 1)\n        x_t = sqrt_alpha_cumprod * x + sqrt_one_minus * noise\n        \n        t_norm = t_idx.float() / timesteps # Model expects t in [0,1]\n\n        optimizer.zero_grad()\n        \n        # --- CORRECTED autocast (positional argument) ---\n        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n            pred = model(x_t, t_norm, c) # Pass the (potentially dropped) label\n            loss = F.mse_loss(pred, noise)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        ema.update()\n        global_step += 1\n\n        if global_step % 200 == 0:\n            pbar.set_description(f\"Epoch {epoch} | loss: {loss.item():.4f}\")\n\n    # --- End of Epoch: Validation Sampling ---\n    if epoch % 5 == 0 or epoch == n_epochs - 1:\n        ema.copy_to(model)\n        model.eval()\n        \n        # Sample 8 different classes (or fewer if you don't have 8)\n        n_sample_classes = min(YOUR_NUM_CLASSES, 8)\n        samples_per_class = 8\n        \n        all_samples = []\n        for class_id in range(n_sample_classes):\n            print(f\"Sampling class {class_id}...\")\n            samples = sample_loop(\n                model=model,\n                schedule=schedule,\n                img_size=img_size,\n                n_samples=samples_per_class,\n                cond_label=class_id,\n                null_class_idx=NULL_CLASS_IDX,\n                guidance_scale=7.5, # Standard guidance scale\n                device=device\n            )\n            all_samples.append(samples)\n        \n        grid_samples = torch.cat(all_samples)\n        grid_samples = (grid_samples + 1) / 2 # Denormalize to [0,1]\n        \n        grid = make_grid(grid_samples, nrow=samples_per_class)\n        save_image(grid, os.path.join(save_dir, f'samples_epoch_{epoch}.png'))\n        print(f'\\n‚úÖ Saved sample grid for epoch {epoch} to {save_dir}')\n\n# --- Final Save ---\nema.store(os.path.join(save_dir, 'ema_shadow.pth'))\nprint('‚úÖ Training complete. Final EMA weights saved to ema_shadow.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:24:43.384940Z","iopub.execute_input":"2025-11-13T10:24:43.385671Z","iopub.status.idle":"2025-11-13T12:37:03.113318Z","shell.execute_reply.started":"2025-11-13T10:24:43.385644Z","shell.execute_reply":"2025-11-13T12:37:03.112494Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nConverting one-hot labels to integers.\nLoaded dataset with 89400 images.\nModel parameters: 4.32M\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0 | loss: 0.1639: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:56<00:00, 12.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 0 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 | loss: 0.1410: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.05it/s]\nEpoch 2 | loss: 0.1101: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.38it/s]\nEpoch 3 | loss: 0.1121: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.79it/s]\nEpoch 4 | loss: 0.1010: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.11it/s]\nEpoch 5 | loss: 0.0697: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 5 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 | loss: 0.0624: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:47<00:00, 14.63it/s]\nEpoch 7 | loss: 0.0902: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:48<00:00, 14.52it/s]\nEpoch 8 | loss: 0.0558: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:48<00:00, 14.42it/s]\nEpoch 9 | loss: 0.0713: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.62it/s]\nEpoch 10 | loss: 0.0615: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:49<00:00, 14.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 10 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 | loss: 0.0477: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.01it/s]\nEpoch 12 | loss: 0.0534: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.19it/s]\nEpoch 13 | loss: 0.0499: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.21it/s]\nEpoch 14 | loss: 0.0424: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.15it/s]\nEpoch 15 | loss: 0.0480: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 15 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16 | loss: 0.0418: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.15it/s]\nEpoch 17 | loss: 0.0482: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.41it/s]\nEpoch 18 | loss: 0.0432: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.17it/s]\nEpoch 19 | loss: 0.0329: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.90it/s]\nEpoch 20 | loss: 0.0388: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 20 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21 | loss: 0.0467: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.20it/s]\nEpoch 22 | loss: 0.0337: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.19it/s]\nEpoch 23 | loss: 0.0408: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.93it/s]\nEpoch 24 | loss: 0.0352: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.15it/s]\nEpoch 25 | loss: 0.0387: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 25 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26 | loss: 0.0392: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.81it/s]\nEpoch 27 | loss: 0.0393: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.01it/s]\nEpoch 28 | loss: 0.0335: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.07it/s]\nEpoch 29 | loss: 0.0307: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.11it/s]\nEpoch 30 | loss: 0.0382: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 30 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31 | loss: 0.0265: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.52it/s]\nEpoch 32 | loss: 0.0247: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.31it/s]\nEpoch 33 | loss: 0.0331: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.07it/s]\nEpoch 34 | loss: 0.0332: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.21it/s]\nEpoch 35 | loss: 0.0389: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 35 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36 | loss: 0.0278: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.18it/s]\nEpoch 37 | loss: 0.0337: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.14it/s]\nEpoch 38 | loss: 0.0288: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.02it/s]\nEpoch 39 | loss: 0.0386: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.02it/s]\nEpoch 40 | loss: 0.0244: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 40 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41 | loss: 0.0334: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.51it/s]\nEpoch 42 | loss: 0.0344: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:47<00:00, 14.63it/s]\nEpoch 43 | loss: 0.0380: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.31it/s]\nEpoch 44 | loss: 0.0296: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.09it/s]\nEpoch 45 | loss: 0.0304: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 45 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46 | loss: 0.0300: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 12.99it/s]\nEpoch 47 | loss: 0.0307: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.11it/s]\nEpoch 48 | loss: 0.0277: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.20it/s]\nEpoch 49 | loss: 0.0300: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.31it/s]\nEpoch 50 | loss: 0.0178: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 50 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51 | loss: 0.0280: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.14it/s]\nEpoch 52 | loss: 0.0230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.50it/s]\nEpoch 53 | loss: 0.0252: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:50<00:00, 13.85it/s]\nEpoch 54 | loss: 0.0285: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.65it/s]\nEpoch 55 | loss: 0.0237: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 55 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56 | loss: 0.0212: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 12.97it/s]\nEpoch 57 | loss: 0.0263: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.22it/s]\nEpoch 58 | loss: 0.0279: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 12.99it/s]\nEpoch 59 | loss: 0.0357: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.01it/s]\nEpoch 60 | loss: 0.0181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 60 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 61 | loss: 0.0380: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 12.96it/s]\nEpoch 62 | loss: 0.0243: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:54<00:00, 12.92it/s]\nEpoch 63 | loss: 0.0210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.04it/s]\nEpoch 64 | loss: 0.0194: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:49<00:00, 14.04it/s]\nEpoch 65 | loss: 0.0241: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:49<00:00, 14.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 65 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 66 | loss: 0.0220: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.05it/s]\nEpoch 67 | loss: 0.0276: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.01it/s]\nEpoch 68 | loss: 0.0266: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.04it/s]\nEpoch 69 | loss: 0.0229: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.17it/s]\nEpoch 70 | loss: 0.0217: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 70 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 71 | loss: 0.0316: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.11it/s]\nEpoch 72 | loss: 0.0187: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.12it/s]\nEpoch 73 | loss: 0.0162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.28it/s]\nEpoch 74 | loss: 0.0214: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.25it/s]\nEpoch 75 | loss: 0.0224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 75 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 76 | loss: 0.0197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.16it/s]\nEpoch 77 | loss: 0.0153: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.18it/s]\nEpoch 78 | loss: 0.0242: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.24it/s]\nEpoch 79 | loss: 0.0241: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.06it/s]\nEpoch 80 | loss: 0.0217: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 80 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 81 | loss: 0.0259: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.12it/s]\nEpoch 82 | loss: 0.0197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.28it/s]\nEpoch 83 | loss: 0.0199: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.20it/s]\nEpoch 84 | loss: 0.0206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.29it/s]\nEpoch 85 | loss: 0.0184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 85 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 86 | loss: 0.0226: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:47<00:00, 14.67it/s]\nEpoch 87 | loss: 0.0230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.63it/s]\nEpoch 88 | loss: 0.0145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.13it/s]\nEpoch 89 | loss: 0.0163: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.59it/s]\nEpoch 90 | loss: 0.0288: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 90 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 91 | loss: 0.0218: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.14it/s]\nEpoch 92 | loss: 0.0166: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.16it/s]\nEpoch 93 | loss: 0.0162: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.51it/s]\nEpoch 94 | loss: 0.0168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.23it/s]\nEpoch 95 | loss: 0.0180: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 95 to /kaggle/working/pixel_diffusion_outputs\n","output_type":"stream"},{"name":"stderr","text":"Epoch 96 | loss: 0.0184: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:52<00:00, 13.30it/s]\nEpoch 97 | loss: 0.0192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:51<00:00, 13.57it/s]\nEpoch 98 | loss: 0.0181: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:49<00:00, 14.15it/s]\nEpoch 99 | loss: 0.0186: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 699/699 [00:53<00:00, 13.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sampling class 0...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 1...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 2...\n","output_type":"stream"},{"name":"stderr","text":"                                                                     \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 3...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Sampling class 4...\n","output_type":"stream"},{"name":"stderr","text":"                                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved sample grid for epoch 99 to /kaggle/working/pixel_diffusion_outputs\n‚úÖ Training complete. Final EMA weights saved to ema_shadow.pth\n","output_type":"stream"}],"execution_count":7}]}